{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data with attention edges\n",
    "\n",
    "__Author:__ Ji Won Park (@jiwoncpark)\n",
    "\n",
    "__Created:__ 3/12/2021\n",
    "\n",
    "__Last run:__ 4/14/2021\n",
    "\n",
    "__Goals:__\n",
    "We visualize the input graph with the edge transparency controlled by the attention weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a GNN for a few epochs to learn some attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n2j.trainval_data.raytracers.cosmodc2_raytracer import CosmoDC2Raytracer\n",
    "from n2j.trainer import Trainer\n",
    "\n",
    "IN_DIR = '../n2j/data'  # where raw data lies\n",
    "TRAIN_HP = [10327, 10450]\n",
    "VAL_HP = [9559]\n",
    "N_TRAIN = 200\n",
    "N_VAL = 100\n",
    "BATCH_SIZE = min(N_TRAIN//5, 25)\n",
    "CHECKPOINT_PATH = None\n",
    "SUB_TARGET = ['final_kappa', ]  # 'final_gamma1', 'final_gamma2']\n",
    "if False:\n",
    "    ##############\n",
    "    # Labels (Y) #\n",
    "    ##############\n",
    "    # Explicitly sample kappas for ~1000 sightlines first (slow)\n",
    "    if False:\n",
    "        kappa_sampler = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                          out_dir='../kappa_sampling',\n",
    "                                          fov=0.85,\n",
    "                                          healpix=10450,\n",
    "                                          n_sightlines=1000,  # keep this small\n",
    "                                          mass_cut=11.0,\n",
    "                                          n_kappa_samples=1000)\n",
    "        kappa_sampler.parallel_raytrace()\n",
    "        kappa_sampler.apply_calibration()\n",
    "    # Use this to infer the mean kappa contribution of new sightlines\n",
    "    for hp in TRAIN_HP:\n",
    "        train_Y_generator = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                              out_dir=f'demo_Y_{hp}',\n",
    "                                              fov=0.85,\n",
    "                                              healpix=hp,\n",
    "                                              n_sightlines=N_TRAIN,  # many more LOS\n",
    "                                              mass_cut=11.0,\n",
    "                                              n_kappa_samples=0,\n",
    "                                              kappa_sampling_dir='../kappa_sampling')  # no sampling\n",
    "        train_Y_generator.parallel_raytrace()\n",
    "        train_Y_generator.apply_calibration()\n",
    "    for hp in VAL_HP:\n",
    "        # Use on a different healpix\n",
    "        val_Y_generator = CosmoDC2Raytracer(in_dir=IN_DIR,\n",
    "                                            out_dir=f'demo_Y_{hp}',\n",
    "                                            fov=0.85,\n",
    "                                            healpix=hp,\n",
    "                                            n_sightlines=N_VAL,  # many more LOS\n",
    "                                            mass_cut=11.0,\n",
    "                                            n_kappa_samples=0,\n",
    "                                            kappa_sampling_dir='../kappa_sampling')  # no sampling\n",
    "        val_Y_generator.parallel_raytrace()\n",
    "        val_Y_generator.apply_calibration()\n",
    "\n",
    "##############\n",
    "# Graphs (X) #\n",
    "##############\n",
    "\n",
    "features = ['galaxy_id', 'ra', 'dec', 'redshift']\n",
    "features += ['ra_true', 'dec_true', 'redshift_true']\n",
    "features += ['ellipticity_1_true', 'ellipticity_2_true']\n",
    "features += ['bulge_to_total_ratio_i']\n",
    "features += ['ellipticity_1_bulge_true', 'ellipticity_1_disk_true']\n",
    "features += ['ellipticity_2_bulge_true', 'ellipticity_2_disk_true']\n",
    "features += ['shear1', 'shear2', 'convergence']\n",
    "features += ['size_bulge_true', 'size_disk_true', 'size_true']\n",
    "features += ['mag_{:s}_lsst'.format(b) for b in 'ugrizY']\n",
    "# Features to train on\n",
    "sub_features = ['ra_true', 'dec_true']\n",
    "sub_features += ['size_true']\n",
    "sub_features += ['mag_{:s}_lsst'.format(b) for b in 'i']\n",
    "trainer = Trainer('cuda', checkpoint_dir='demo_run', seed=1113)\n",
    "\n",
    "trainer.load_dataset(dict(features=features,\n",
    "                          raytracing_out_dirs=[f'demo_Y_{hp}' for hp in TRAIN_HP],\n",
    "                          healpixes=TRAIN_HP,\n",
    "                          n_data=[N_TRAIN]*len(TRAIN_HP),\n",
    "                          aperture_size=1.0,\n",
    "                          stop_mean_std_early=True,\n",
    "                          in_dir=IN_DIR),\n",
    "                     sub_features=sub_features,\n",
    "                     sub_target=SUB_TARGET,\n",
    "                     is_train=True,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     )\n",
    "# FIXME: must be run after train\n",
    "trainer.load_dataset(dict(features=features,\n",
    "                          raytracing_out_dirs=[f'demo_Y_{hp}' for hp in VAL_HP],\n",
    "                          healpixes=VAL_HP,\n",
    "                          n_data=[N_VAL]*len(VAL_HP),\n",
    "                          aperture_size=1.0,\n",
    "                          in_dir=IN_DIR),\n",
    "                     sub_features=sub_features,\n",
    "                     sub_target=SUB_TARGET,\n",
    "                     is_train=False,\n",
    "                     batch_size=BATCH_SIZE,  # FIXME: must be same as train\n",
    "                     )\n",
    "trainer.configure_loss_fn('FullRankGaussianNLL')\n",
    "trainer.configure_model('GATNet',\n",
    "                        {'hidden_channels': 64,\n",
    "                         'n_layers': 3,\n",
    "                         'dropout': 0.0,\n",
    "                         'kwargs': {'concat': False, 'heads': 2}})\n",
    "trainer.configure_optim(20,\n",
    "                        {'lr': 1.e-5, 'weight_decay': 1.e-5},\n",
    "                        {'factor': 0.75, 'min_lr': 1.e-7, 'patience': 200, 'verbose': True})\n",
    "if CHECKPOINT_PATH:\n",
    "    trainer.load_state(CHECKPOINT_PATH)\n",
    "trainer.train(n_epochs=5, eval_every=2)\n",
    "print(trainer)\n",
    "# Save final validation metrics\n",
    "summary = trainer.eval_posterior(epoch_i=trainer.epoch,\n",
    "                                 n_samples=200,\n",
    "                                 n_mc_dropout=20,\n",
    "                                 on_train=False)\n",
    "np.save(os.path.join(trainer.checkpoint_dir, 'summary.npy'), summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which sightlines should we plot? Maybe we want to check out the overdense ones, with high $\\kappa$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = np.load('demo_run/summary.npy', allow_pickle=True).item()\n",
    "\n",
    "for i, k in enumerate(summary['y_val'][:, 0]):\n",
    "    if k > 0.05:\n",
    "        print(i, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now color the nodes by the redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = 0\n",
    "# Make sure dataset is not standardized and is in real units\n",
    "trainer.val_dataset.transform_X = None\n",
    "trainer.val_dataset.transform_Y = None\n",
    "sample_data = trainer.val_dataset[data_i]\n",
    "pointings = trainer.val_dataset.Y\n",
    "z_src = pointings.iloc[data_i]['z']\n",
    "print(z_src)\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = z_src\n",
    "plt.hist(z, bins=np.linspace(0, 2.5, 20))\n",
    "plt.axvline(z_src, color='tab:red', label='Source z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can additionally scale the node size by the (inverse) i-band magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "\n",
    "data_i = 0\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "sample_data = trainer.val_dataset[data_i]\n",
    "pointings = trainer.val_dataset.Y\n",
    "sample_networkx = to_networkx(sample_data)\n",
    "n_nodes = sample_data.x.shape[0]\n",
    "# Color by redshift\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = pointings.iloc[data_i]['z']\n",
    "scaled_z = (z - z.min())/(z.max() - z.min())  # scale 0 to 1 for colormap\n",
    "node_color = cmap(scaled_z)\n",
    "# Make brighter nodes bigger\n",
    "mag = -sample_data.x[:, -3].numpy()\n",
    "mag[0] = np.mean(mag[1:])\n",
    "node_size = (mag - mag.min())/(mag.max() - mag.min())*30 + 5\n",
    "node_size[0] = 50\n",
    "\n",
    "nx.draw(sample_networkx, pos=dict(zip(range(n_nodes), sample_data.x[:, 4:6].tolist())),\n",
    "        width=0.2, edge_color='tab:gray', arrowsize=1, alpha=1.0, \n",
    "        node_color=node_color, node_size=node_size)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=z.min(), vmax=z.max()))\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm)\n",
    "\n",
    "print(sample_data.x.shape, sample_data.edge_index.shape)\n",
    "print(sample_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_edge_index = summary['edge_index']\n",
    "sample_data = trainer.val_dataset[data_i]\n",
    "\n",
    "# Get a particular subgraph in this dataset\n",
    "subgraph_edge_index = sample_data.edge_index.cpu().numpy()\n",
    "# Find idx of the first edge of the subgraph\n",
    "first_i, first_j = subgraph_edge_index[:, 0]\n",
    "print(first_i, first_j)\n",
    "first_idx = np.where((attention_edge_index[0, :] == first_i) & (attention_edge_index[1, :] == first_j))[0][0]\n",
    "# Find idx of the last edge of the subgraph\n",
    "last_i, last_j = subgraph_edge_index[:, -1]\n",
    "print(last_i, last_j)\n",
    "last_idx = np.where((attention_edge_index[0, :] == last_i) & (attention_edge_index[1, :] == last_j))[0][0]\n",
    "print(first_idx, last_idx)\n",
    "\n",
    "# Slice the attention weights for this subgraph (averaged across the 4 heads)\n",
    "attention_weights = summary['w'][first_idx:last_idx+1, :].mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary['edge_index'].shape, summary['w'].shape, subgraph_edge_index.shape, attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_edge_index[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add attention weights from node a node b to weights from node b to node a\n",
    "plot_edge = np.zeros(subgraph_edge_index.shape[1]).astype(bool)\n",
    "for i in range(subgraph_edge_index.shape[1]):\n",
    "    a, b = subgraph_edge_index[:, i]\n",
    "    if a < b:\n",
    "        plot_edge[i] = True\n",
    "        find = np.where((attention_edge_index[0, :] == b) & (attention_edge_index[1, :] == a))[0]\n",
    "        if len(find) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            reverse_i = find[0]\n",
    "            attention_weights[i] += attention_weights[reverse_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "\n",
    "data_i = 0\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "sample_data = train_XY[data_i]\n",
    "sample_networkx = to_networkx(sample_data)\n",
    "n_nodes = sample_data.x.shape[0]\n",
    "# Color by redshift\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = pointings.iloc[data_i]['z']\n",
    "scaled_z = (z - z.min())/(z.max() - z.min())  # scale 0 to 1 for colormap\n",
    "node_color = cmap(scaled_z)\n",
    "# Make brighter nodes bigger\n",
    "mag = -sample_data.x[:, -3].numpy()\n",
    "mag[0] = np.mean(mag[1:])\n",
    "node_size = (mag - mag.min())/(mag.max() - mag.min())*30 + 5\n",
    "node_size[0] = 50\n",
    "# Control edge transparency with attention weights\n",
    "edge_color = attention_weights[plot_edge]\n",
    "edge_color = edge_color/np.sum(edge_color)\n",
    "edge_cmap = 'greys'\n",
    "\n",
    "nx.draw(sample_networkx, pos=dict(zip(range(n_nodes), sample_data.x[:, 4:6].tolist())),\n",
    "        width=0.2,\n",
    "        # Edge\n",
    "        edge_color=edge_color, \n",
    "        edge_cmap=matplotlib.cm.get_cmap('Greys_r'), \n",
    "        edgelist=np.array(sample_networkx.edges())[plot_edge, :],\n",
    "        arrowsize=1,  \n",
    "        # Node\n",
    "        node_color=node_color, node_size=node_size)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=z.min(), vmax=z.max()))\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm)\n",
    "\n",
    "print(sample_data.x.shape, sample_data.edge_index.shape)\n",
    "print(sample_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(attention_weights, density=True, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(edge_color, density=True, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_mean = np.median(edge_color)\n",
    "edge_cmap = matplotlib.cm.get_cmap('Greys_r')\n",
    "color_mean = edge_cmap(edge_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "\n",
    "data_i = 0\n",
    "cmap = matplotlib.cm.get_cmap('jet')\n",
    "sample_data = trainer.val_dataset[data_i]\n",
    "sample_networkx = to_networkx(sample_data)\n",
    "n_nodes = sample_data.x.shape[0]\n",
    "# Color by redshift\n",
    "z = sample_data.x[:, 3].numpy()\n",
    "z[0] = pointings.iloc[data_i]['z']\n",
    "scaled_z = (z - z.min())/(z.max() - z.min())  # scale 0 to 1 for colormap\n",
    "node_color = cmap(scaled_z)\n",
    "# Make brighter nodes bigger\n",
    "mag = -sample_data.x[:, -3].numpy()\n",
    "mag[0] = np.mean(mag[1:])\n",
    "node_size = (mag - mag.min())/(mag.max() - mag.min())*30 + 5\n",
    "node_size[0] = 50\n",
    "\n",
    "nx.draw(sample_networkx, pos=dict(zip(range(n_nodes), sample_data.x[:, 4:6].tolist())),\n",
    "        width=0.2, \n",
    "        edge_color=color_mean, arrowsize=1,\n",
    "        node_color=node_color, node_size=node_size)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=z.min(), vmax=z.max()))\n",
    "sm.set_array([])\n",
    "plt.colorbar(sm)\n",
    "\n",
    "print(sample_data.x.shape, sample_data.edge_index.shape)\n",
    "print(sample_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (n2j)",
   "language": "python",
   "name": "n2j"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
